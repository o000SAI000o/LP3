{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd3fea-220a-4d31-bd90-857cfe721a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# BANK CUSTOMER CHURN PREDICTION (Complete Mini Project)\n",
    "# --------------------------------------------------------------\n",
    "# Problem Statement:\n",
    "# ...\n",
    "# Tasks Covered:\n",
    "# 1. Read the dataset\n",
    "# 2. Distinguish feature and target set and split data\n",
    "# 3. Normalize the data\n",
    "# 4. Build & Train ANN Model + Implement improvements\n",
    "# 5. Print Accuracy Score & Confusion Matrix\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# BANK CUSTOMER CHURN PREDICTION USING ARTIFICIAL NEURAL NETWORK (ANN)\n",
    "# ------------------------------------------------------------\n",
    "# Aim: Predict whether a bank customer will leave the bank (Churn = 1) or stay (0)\n",
    "# Steps: Load → Preprocess → Train-Test Split → Normalize → Build ANN → Evaluate\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1. PRE-PROCESSING\n",
    "# -----------------------------\n",
    "'''In this step, we separate the independent features (X) and the target variable (y).\n",
    "Columns like RowNumber, CustomerId, and Surname do not help in prediction and are removed.\n",
    "Categorical columns such as Geography and Gender are converted into numeric format using One-Hot Encoding.'''\n",
    "\n",
    "# Select useful features and target\n",
    "X = df[['CreditScore','Geography','Gender','Age','Tenure','Balance',\n",
    "        'NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary']]\n",
    "y = df['Exited']   # Target → 1 = Churn, 0 = Not Churn\n",
    "\n",
    "# Convert categorical columns into numeric values\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. TRAIN-TEST SPLIT\n",
    "# -----------------------------\n",
    "'''train_test_split() divides the dataset into training and testing parts.\n",
    "X_train and y_train will be used to train the ANN model, \n",
    "while X_test and y_test will be used to check how well the model performs on unseen data.\n",
    "test_size=0.2 means 80% training and 20% testing. random_state=42 ensures reproducibility.'''\n",
    "\n",
    "# Split data into train (80%) and test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. DATA NORMALIZATION\n",
    "# -----------------------------\n",
    "'''ANN models perform better when numerical features are on a similar scale.\n",
    "StandardScaler transforms all feature values so that they have mean=0 and std=1, \n",
    "leading to faster learning and better model accuracy.'''\n",
    "\n",
    "# Normalize the feature values\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. MODEL TRAINING (ANN)\n",
    "# -----------------------------\n",
    "!pip install tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "'''This block creates and trains the Artificial Neural Network model.\n",
    "\n",
    "Sequential() initializes the ANN as a sequence of layers. Dense() is used to add fully connected layers, \n",
    "where each neuron receives input from all neurons of the previous layer. The first Dense layer specifies \n",
    "input_dim=X_train.shape[1] to match the number of input features.\n",
    "\n",
    "ReLU activation allows the ANN to learn non-linear patterns, while Dropout(0.2) helps prevent overfitting \n",
    "by randomly disabling 20% of neurons during training. The output layer uses a sigmoid activation function \n",
    "to return values between 0 and 1 for binary classification (Churn/Not Churn).\n",
    "\n",
    "The compile() function configures the model with the Adam optimizer and binary_crossentropy loss function, \n",
    "both suitable for binary classification tasks. Finally, fit() trains the ANN using the training data for \n",
    "20 epochs with a batch size of 32 and uses 20% of training data for validation during training.'''\n",
    "\n",
    "\n",
    "# Initialize ANN Model\n",
    "model = Sequential()\n",
    "\n",
    "# Input + Hidden Layer 1\n",
    "model.add(Dense(16, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Hidden Layer 2\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid outputs probability between 0 and 1\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5. MODEL EVALUATION\n",
    "# -----------------------------\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "'''This block evaluates the performance of the trained ANN model.\n",
    "\n",
    "The predict() function generates probability values for each test sample, so a threshold of 0.5 is applied \n",
    "to convert them into binary class labels (0 = Not Churn, 1 = Churn). The accuracy_score() function measures \n",
    "the percentage of correct predictions made by the model.\n",
    "\n",
    "confusion_matrix() returns a matrix showing True Positives, True Negatives, False Positives, and False Negatives, \n",
    "helping to analyze model performance for each class. classification_report() provides a detailed summary containing \n",
    "precision, recall, F1-score, and support, giving deeper insight into how well the model performs across both classes.'''\n",
    "\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Accuracy Score\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
